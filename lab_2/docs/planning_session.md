# Планирование с AI-ассистентом: NLP для Phishing Detection

## Исходный промпт

```
Мне нужно адаптировать ML-пайплайн для классификации фишинговых email на основе текста писем.

НЕ ПИШИ КОД СРАЗУ. Создай детальный план адаптации:

1. Какие NLP preprocessing шаги нужны для email текстов?
2. Как обрабатывать специфику email (URLs, email addresses, HTML tags)?
3. Какие методы векторизации подходят для phishing detection?
4. Какие алгоритмы классификации лучше для текстов?
5. Как адаптировать EDA для текстовых данных?
6. Какие метрики важны для phishing detection?

```

Ниже представлен практический план адаптации ML-пайплайна под ваш проект (CSV-файлы с train/test, Jupyter-ноутбук, CLI-скрипт для инференса). План охватывает весь цикл — от предобработки до оценки и EDA.

#### 1. Предобработка текста email (NLP preprocessing)

- **Нормализация:**
  - Декодирование HTML-сущностей (&amp; → & и т.д.).
  - Приведение к форме Unicode NFC, удаление невидимых символов (zero-width spaces).
  - Перевод в нижний регистр (с возможностью сохранить признак смешанного регистра).
- **Очистка:**
  - Удаление HTML-тегов с сохранением видимого текста и alt-атрибутов.
  - Замена URL, email-адресов, номеров телефонов, сумм денег и IP на специальные токены (URL, EMAIL, PHONE, MONEY, IP).
  - Нормализация чисел (NUM), дат и времени (DATE, TIME).
  - Обработка повторяющихся символов и гомоглифов (замена похожих unicode-символов на ASCII-аналоги или маркировка как подозрительные).
  - Извлечение текста из multipart-сообщений (приоритет text/plain, в крайнем случае — парсинг text/html).
- **Токенизация и лемматизация:**
  - Определение языка письма (langid/pyCLD3) и выбор соответствующей лемматизации (pymorphy3 или spaCy для русского, spaCy/en-core для английского).
  - Сохранение доменных токенов без изменений.
- **Стоп-слова:**
  - Стандартные списки + эксперименты с их отключением (многие фишинговые фразы могут содержать «типичные» стоп-слова).
- **N-граммы:**
  - Словные: 1–3-граммы.
  - Символьные: 3–5-граммы (для устойчивости к обфускации).
- **Ручная инженерия признаков:**
  - Количество ссылок, доменов, подозрительных TLD (.top, .xyz, .cfd), длина доменов, наличие punycode.
  - Количество email-адресов, совпадение доменов отправителя и ссылок.
  - Статистика: количество восклицательных знаков, слов в ВЕРХНЕМ РЕГИСТРЕ, эмодзи, денежных сумм.
  - Длина письма, средняя длина слова, доля уникальных токенов.
  - Признаки наличия триггерных фраз («срочно», «подтвердите аккаунт», «ваш аккаунт заблокирован», urgent, verify и т.п.).
  - HTML-признаки: скрытый текст, формы, скрипты, meta-redirect, onclick.
  - Бинарные флаги: наличие вложений, изображений, не-ASCII символов.

#### 2. Обработка особенностей email

- **URL:**
  - Извлечение всех ссылок, замена в тексте на токен URL.
  - Дополнительные признаки: TLD, длина, наличие IP вместо домена, порт, параметры query, сокращатели ссылок, гомографические домены.
- **Email-адреса:**
  - Замена на токен EMAIL + признаки домена (совпадение с официальными брендами, подозрительные домены).
- **HTML:**
  - Безопасный парсинг (BeautifulSoup/lxml), извлечение текста и alt-атрибутов.
  - Признаки: количество ссылок без текста («click here»), скрытый текст, наличие форм и скриптов.
- **Обфускация:**
  - Нормализация гомоглифов, удаление/маркировка zero-width символов и вставленных пробелов между буквами.
- **Тема письма (subject):**
  - Добавление как префикса «subject: …» к основному тексту + отдельные признаки (RE:/FWD:, эмодзи, капс, восклицания).

#### 3. Векторизация текста

- **Классические методы:**
  - TF-IDF по словам и n-граммам (1–3) + символьные n-граммы (3–5).
  - Отдельный TF-IDF для доменов и путей URL.
- **Эмбеддинги:**
  - Усреднённые FastText/word2vec или sentence-эмбеддинги (LaBSE, multilingual MiniLM).
- **Гибридный подход:**
  - Конкатенация TF-IDF (слова + символы) + TF-IDF доменов + масштабированные ручные признаки.
  - При использовании трансформеров — CLS-токен + отдельная ветка для числовых признаков.

#### 4. Алгоритмы классификации

- **Базовые (быстрые и эффективные):**
  - Логистическая регрессия (L2-регуляризация, class_weight='balanced').
  - Linear SVM (LinearSVC или SGDClassifier) — часто показывает лучшие результаты на TF-IDF.
  - Complement Naive Bayes.
- **Продвинутые:**
  - Градиентный бустинг (LightGBM, XGBoost, CatBoost) — удобно комбинировать разнотипные признаки.
  - Трансформеры (RuBERT, mBERT, XLM-R) при наличии ресурсов.
- **Рекомендуемая последовательность:**
  1. Baseline: TF-IDF (слова + символы) + Linear SVM / Logistic Regression.
  2. Улучшение: добавление ручных признаков + LightGBM.
  3. При необходимости — fine-tuning трансформера.

#### 5. Исследовательский анализ данных (EDA)

- Проверка баланса классов, дубликатов, пустых текстов, распределения языков и длин писем.
- Топ слов и n-грамм по классам, наиболее дискриминативные фразы (PMI, χ²).
- Анализ URL/HTML: распределение TLD, количества ссылок, типов якорей.
- Сравнение статистик (восклицания, капс, эмодзи) между классами.
- Визуализация: boxplot числовых признаков, t-SNE/UMAP на уменьшенном TF-IDF.
- Анализ ошибок: матрица ошибок, разбор ложных срабатываний и пропусков.

#### 6. Метрики оценки

- Основные: F1-score (macro и по классу phishing), Precision, Recall.
- AUC-метрики: ROC-AUC и особенно PR-AUC (при дисбалансе).
- Порог принятия решения: настройка под требуемый Recall (например, ≥0.95) при приемлемом Precision.
- Контроль FPR на легитимных письмах.
- Валидация: Stratified K-Fold, при возможности — разделение по доменам отправителя.

## Архитектурные решения

- **Предобработка:** лемматизация (сохраняет семантику) + базовые шаги очистки, без агрессивной обработки чисел и стоп-слов.
- **Векторизация:** TF-IDF (вариации с разными n-граммами).
- **Модель:** Linear SVM — показала наилучший weighted average F1-score.
- **Метрики:** Precision и Recall оказались очень близкими, модель хорошо сбалансирована.

Этот план позволяет поэтапно развивать решение: начать с простого baseline, постепенно добавлять признаки и усложнять модель.
